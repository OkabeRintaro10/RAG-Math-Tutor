{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_topics = [\"bike\"]\n",
    "valid_topics = [\"phone\", \"tablet\", \"computer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4b8782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Introducing the Galaxy Tab S7, a sleek and sophisticated device that seamlessly combines \\\n",
    "cutting-edge technology with unparalleled design. With a stunning 5.1-inch Quad HD Super AMOLED display, \\\n",
    "every detail comes to life in vibrant clarity. The Samsung Galaxy S7 boasts a powerful processor, \\\n",
    "ensuring swift and responsive performance for all your tasks. \\\n",
    "Capture your most cherished moments with the advanced camera system, which delivers stunning photos in any lighting conditions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30fe7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab4a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryefoxlime/MathTutor/.venv/lib/python3.12/site-packages/guardrails/validator_service/__init__.py:84: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValidationOutcome(\n",
      "    call_id='127258179664576',\n",
      "    raw_llm_output='What is Fourier series?',\n",
      "    validation_summaries=[],\n",
      "    validated_output='What is Fourier series?',\n",
      "    reask=None,\n",
      "    validation_passed=True,\n",
      "    error=None\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import guardrails as gd\n",
    "from guardrails.hub import RestrictToTopic\n",
    "from guardrails.errors import ValidationError\n",
    "# Create the Guard with the OnTopic Validator\n",
    "# Create the Guard with the OnTopic Validator\n",
    "guard = gd.Guard.from_string(\n",
    "    validators=[\n",
    "        RestrictToTopic(\n",
    "            valid_topics=[\n",
    "                \"math\",\n",
    "                \"algebra\",\n",
    "                \"calculus\",\n",
    "                \"geometry\",\n",
    "                \"equations\",\n",
    "                \"statistics\",\n",
    "                \"probability\",\n",
    "                \"theorems\",\n",
    "                \"proofs\",\n",
    "            ],\n",
    "            # invalid_topics=invalid_topics,\n",
    "            device=device,\n",
    "            disable_classifier=False,\n",
    "            disable_llm=True,\n",
    "            on_fail=\"exception\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Test with a given text\n",
    "try:\n",
    "    test = guard.parse(\n",
    "        llm_output=\"What is Fourier series?\",\n",
    "    )\n",
    "    print(test)\n",
    "except ValidationError as e:\n",
    "    print(e)\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74df194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "import json\n",
    "def openrouter_llm_callable_FIXED(prompt, topics):\n",
    "    \"\"\"\n",
    "    This function now re-creates the JSON prompt, just like\n",
    "    the internal Guardrails code.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Get the topics, which Guardrails passes in kwargs\n",
    "    \n",
    "    print(\"--- üïµÔ∏è‚Äç‚ôÇÔ∏è DEBUGGING VALIDATOR ---\")\n",
    "    print(f\"Validator received text:\\n{prompt[:100]}...\")  # Print first 100 chars\n",
    "    print(f\"Validator is using topics:\\n{topics}\")\n",
    "\n",
    "    # 2. Build the special JSON-forcing prompt\n",
    "    # This is the same prompt you just found!\n",
    "    json_prompt = f\"\"\"\n",
    "        Given a text and a list of topics, return a valid json list of which topics are present in the text. If none, just return an empty list.\n",
    "\n",
    "        Output Format:\n",
    "        -------------\n",
    "        {{\"topics_present\": []}}\n",
    "\n",
    "        Text:\n",
    "        ----\n",
    "        \"{prompt}\"\n",
    "\n",
    "        Topics: \n",
    "        ------\n",
    "        {topics}\n",
    "\n",
    "        Result:\n",
    "        ------ \n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Validator is sending this JSON prompt to Mistral...\")\n",
    "\n",
    "    # 3. Call the LLM with the *new* JSON prompt\n",
    "    try:\n",
    "        response = litellm.completion(\n",
    "            model=\"openrouter/google/gemma-3-4b-it\",\n",
    "            messages=[{\"role\": \"user\", \"content\": json_prompt}],\n",
    "            api_base=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "            # We must force the model to return JSON\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "        )\n",
    "        \n",
    "        raw_response = response.choices[0].message.content\n",
    "        print(f\"Validator got this raw JSON response:\\n{raw_response}\")\n",
    "\n",
    "        # 4. Parse the JSON and return the list\n",
    "        # We need to clean the response to find the JSON\n",
    "        json_str = raw_response[raw_response.find(\"{\") : raw_response.rfind(\"}\") + 1]\n",
    "        json_data = json.loads(json_str)\n",
    "\n",
    "        # This is the list Guardrails is expecting\n",
    "        topics_found = json_data.get(\"topics_present\", [])\n",
    "\n",
    "        print(f\"Validator is returning this list: {topics_found}\")\n",
    "        print(\"-------------------------------\")\n",
    "\n",
    "        return topics_found\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Validator failed to parse JSON: {e}\")\n",
    "        return []  # Return empty list on failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86bb06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from guardrails import Guard\n",
    "from guardrails.errors import ValidationError\n",
    "from guardrails.hub import RestrictToTopic  # We will only use this validator\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Global Client for Embeddings ---\n",
    "# This client is used by BOTH guards for semantic search.\n",
    "try:\n",
    "    embedding_client = OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Failed to initialize embedding client: {e}\")\n",
    "    embedding_client = None\n",
    "\n",
    "\n",
    "class InputGuard:\n",
    "    \"\"\"\n",
    "    Validates the user's INPUT.\n",
    "    Checks if the query IS a valid math topic.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        if not embedding_client:\n",
    "            raise ConnectionError(\"Embedding client not initialized.\")\n",
    "\n",
    "        self.guard = Guard().use(\n",
    "            RestrictToTopic(\n",
    "                valid_topics=[\n",
    "                    \"math\",\n",
    "                    \"algebra\",\n",
    "                    \"calculus\",\n",
    "                    \"geometry\",\n",
    "                    \"equations\",\n",
    "                    \"statistics\",\n",
    "                    \"probability\",\n",
    "                    \"theorems\",\n",
    "                    \"proofs\",\n",
    "                ],\n",
    "                # invalid_topics=invalid_topics,\n",
    "                device=device,\n",
    "                llm_callable=openrouter_llm_callable_FIXED,\n",
    "                disable_classifier=False,\n",
    "                disable_llm=False,\n",
    "                on_fail=\"reask\",\n",
    "            )\n",
    "        )\n",
    "        self.embedding_client = embedding_client\n",
    "\n",
    "    def validate(self, text_to_validate: str):\n",
    "        \"\"\"\n",
    "        Validates the user's question string.\n",
    "        Raises ValidationError on failure.\n",
    "        \"\"\"\n",
    "        validation_result = self.guard.parse(\n",
    "            llm_output=text_to_validate,\n",
    "            # llm_api=self.embedding_client\n",
    "        )\n",
    "\n",
    "        if not validation_result.validation_passed:\n",
    "            raise ValidationError(\"Input is not a math-related topic.\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "class OutputGuard:\n",
    "    \"\"\"\n",
    "    Validates the LLM's OUTPUT.\n",
    "    Checks if the response IS a refusal.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        if not embedding_client:\n",
    "            raise ConnectionError(\"Embedding client not initialized.\")\n",
    "\n",
    "        # [MODIFICATION] We use the same validator, but in \"reverse\"\n",
    "        self.guard = Guard().use(\n",
    "            RestrictToTopic(\n",
    "                # We check if the response is semantically\n",
    "                # similar to one of these invalid topics.\n",
    "                invalid_topics=[\n",
    "                    \"I don't know\",\n",
    "                    \"I cannot answer\",\n",
    "                    \"I'm sorry, I can't\",\n",
    "                    \"I am not programmed to\",\n",
    "                    \"I don't have enough information\",\n",
    "                    \"As an AI, I cannot help with that\",\n",
    "                ],\n",
    "                # Force fast, non-LLM embedding search\n",
    "                device=device,\n",
    "                llm_callable=openrouter_llm_callable_FIXED,\n",
    "                disable_classifier=True,\n",
    "                disable_llm=False,\n",
    "                # This time, on_fail=\"noop\" because we\n",
    "                # check the validation result manually.\n",
    "                on_fail=\"reask\",\n",
    "            )\n",
    "        )\n",
    "        self.embedding_client = embedding_client\n",
    "\n",
    "    def validate(self, text_to_validate: str):\n",
    "        \"\"\"\n",
    "        Validates the LLM's response string.\n",
    "        Raises ValidationError on failure.\n",
    "        \"\"\"\n",
    "        validation_result = self.guard.parse(\n",
    "            llm_output=text_to_validate,\n",
    "        )\n",
    "\n",
    "        # [REVERSE LOGIC]\n",
    "        # We used `invalid_topics`. This means:\n",
    "        # PASSED = The text was NOT a refusal. (This is good!)\n",
    "        # FAILED = The text WAS a refusal. (This is bad!)\n",
    "\n",
    "        if not validation_result.validation_passed:\n",
    "            # The guard FAILED, meaning it found a refusal.\n",
    "            # So, we raise an error.\n",
    "            print(validation_result)\n",
    "            raise ValidationError(\"The LLM refused to answer.\")\n",
    "\n",
    "        # The guard PASSED, meaning the text was clean.\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "183d186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_g = InputGuard()\n",
    "output_g = OutputGuard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83f5a4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryefoxlime/MathTutor/.venv/lib/python3.12/site-packages/guardrails/validator_service/__init__.py:84: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üïµÔ∏è‚Äç‚ôÇÔ∏è DEBUGGING VALIDATOR ---\n",
      "Validator received text:\n",
      "What is Fourier series?...\n",
      "Validator is using topics:\n",
      "['geometry', 'theorems', 'algebra', 'statistics', 'probability', 'equations', 'math', 'calculus', 'proofs']\n",
      "Validator is sending this JSON prompt to Mistral...\n",
      "Validator got this raw JSON response:\n",
      "{\"topics_present\": [\"math\"]}\n",
      "Validator is returning this list: ['math']\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_g.validate(\"What is Fourier series?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cffd2f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üïµÔ∏è‚Äç‚ôÇÔ∏è DEBUGGING VALIDATOR ---\n",
      "Validator received text:\n",
      "Introducing the Galaxy Tab S7, a sleek and sophisticated device that seamlessly combines cutting-edg...\n",
      "Validator is using topics:\n",
      "['As an AI, I cannot help with that', 'I am not programmed to', \"I don't know\", 'I cannot answer', \"I'm sorry, I can't\", \"I don't have enough information\"]\n",
      "Validator is sending this JSON prompt to Mistral...\n",
      "Validator got this raw JSON response:\n",
      "{}\n",
      "Validator is returning this list: []\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_g.validate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe757ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathtutor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
